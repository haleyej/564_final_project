{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worst-preference",
   "metadata": {},
   "source": [
    "<h1>SI 564 Final Project: Trails in U.S. National Parks</h1>\n",
    "<p>Haley Johnson</p>\n",
    "\n",
    "<p>Code to create normalized database tables from All Trails dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "needed-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine \n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-latitude",
   "metadata": {},
   "source": [
    "<h2>Database Diagram</h2>\n",
    "<p><a href = \"https://www.kaggle.com/datasets/planejane/national-park-trails\">National Parks data</a></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "modified-corner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"nat_parks_erd.png\" width=\"800\" height=\"800\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"nat_parks_erd.png\", width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-rover",
   "metadata": {},
   "source": [
    "<h2>Connect to SQL</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "supreme-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f'mysql+pymysql://haleyej-rw:{password}@34.134.16.183:14192/nat_parks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-liberia",
   "metadata": {},
   "source": [
    "<h2>Split Data Into Tables</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "viral-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"trails_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "limiting-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area_name'] = df['area_name'].apply(lambda s: np.where(s == 'Congaree National Park Wilderness', 'Congaree', s))\n",
    "\n",
    "not_nps = ['Fort Pickens National Park', 'Clayton Co International Park, Jonesboro GA', \n",
    "           'Fort Hunt National Park', 'Wolf Trap National Park for the Performing Arts']\n",
    "\n",
    "df['valid'] = df['area_name'].apply(lambda s: s not in not_nps)\n",
    "\n",
    "df = df[df['valid'] == True]\n",
    "df = df.drop(columns = ['valid', 'trail_id', 'city_name', 'country_name', '_geoloc', 'activities', \n",
    "                        'num_reviews', 'features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accessory-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['area_name'] = df['area_name'].str.replace(\" National Park\", \"\")\n",
    "df['area_name'] = df['area_name'].str.replace(\" National Park and Preserve\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "broad-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['state_name'] = df['state_name'].astype(str)\n",
    "df['state_name'] = df['state_name'].apply(lambda s: np.where(s == 'Maui', 'Hawaii', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "naked-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(df, col):\n",
    "    '''\n",
    "    Turns column in the dataframe\n",
    "    into a new dataframe that just\n",
    "    contains the unique values of \n",
    "    that column\n",
    "    \n",
    "    Function is used to split\n",
    "    dataframe into smaller tables\n",
    "    for normalization\n",
    "    \n",
    "    Returns a new dataframe\n",
    "    '''\n",
    "    temp = df[col].unique()\n",
    "    df = pd.DataFrame(temp, columns = [col])\n",
    "    df = df.reset_index()\n",
    "    df = df.rename(columns = {'index': 'id'})\n",
    "    df['id'] = df['id'].apply(lambda s: s + 1)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sustainable-pottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_df = create_table(df, 'area_name')\n",
    "states_df = create_table(df, 'state_name')\n",
    "routes_df = create_table(df, 'route_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-valuation",
   "metadata": {},
   "source": [
    "<h3>Trails Table</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "confirmed-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = df[df['units'] == 'm']\n",
    "imperial = df[df['units'] == 'i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "floral-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meters_to_yards(s):\n",
    "    '''\n",
    "    Takes in column of dataframe \n",
    "    \n",
    "    Convers meters to yards\n",
    "    '''\n",
    "    return s * 1.09361\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "atmospheric-accounting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-5803d4a6adb9>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metric['elevation_gain'] = metric['elevation_gain'].apply(meters_to_yards)\n",
      "<ipython-input-13-5803d4a6adb9>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metric['length'] = metric['length'].apply(meters_to_yards)\n"
     ]
    }
   ],
   "source": [
    "metric['elevation_gain'] = metric['elevation_gain'].apply(meters_to_yards)\n",
    "metric['length'] = metric['length'].apply(meters_to_yards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "musical-congress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([imperial, metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "optimum-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-structure",
   "metadata": {},
   "source": [
    "<h2>Normalize</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "prepared-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df1, df2, target, fk):\n",
    "    '''\n",
    "    Normalize tables to prepare for SQL\n",
    "    puts foreign keys into main table\n",
    "    \n",
    "    Removes data that have been \n",
    "    normlized out from the main \n",
    "    datafraame\n",
    "    \n",
    "    Connects main table to supporting\n",
    "    tables wit\n",
    "    \n",
    "    Takes in four arguments:\n",
    "    two dataframes that are being marged, \n",
    "    the column used to merge them\n",
    "    the foreign key connecting the table\n",
    "    \n",
    "    Return a dataframe with the \n",
    "    foreign key normalized\n",
    "    '''\n",
    "    df1 = df1.merge(df2, on = target)\n",
    "    df1 = df1.rename(columns = {'id': fk})\n",
    "    df1 = df1.drop(columns = target)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "primary-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [(states_df, 'state_name', 'state_id'), (routes_df, 'route_type', 'route_type_id'),\n",
    "           (parks_df, 'area_name', 'park_id')]\n",
    "           \n",
    "for target in targets:\n",
    "    df = normalize(df, target[0], target[1], target[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "recorded-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "parks_df = parks_df.rename(columns = {'area_name': 'park'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "simple-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "df = df.rename(columns = {'index': 'id'})\n",
    "df['id'] = df['id'].apply(lambda s: s + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-browse",
   "metadata": {},
   "source": [
    "<h2>Write To SQL</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "lightweight-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(\"trails\", con = engine, index = False)\n",
    "states_df.to_sql(\"states\", con = engine, index = False)\n",
    "parks_df.to_sql(\"parks\", con = engine, index = False)\n",
    "routes_df.to_sql(\"route_types\", con = engine, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-telling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
